{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HEHAnw0ZQ14"
   },
   "source": [
    "# 다중 회귀분석 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H32b7FVRZcMY"
   },
   "source": [
    "python의 scikit-learn 패키지를 이용해 다중 회귀분석을 직접 실행해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyAsdYNkg-Dw"
   },
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jywZfSTeh3mm"
   },
   "source": [
    "Scikit-learn에서는 데이터 분석 연습을 위한 몇 가지의 toy dataset을 제공하고 있다. 그 중 이번 시간에 사용할 데이터셋은 diabetes dataset이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9QtVmOqifGT"
   },
   "source": [
    "Diabetes dataset은 당뇨병 환자들의 1년간 당뇨병 진행 변화에 대한 데이터이다. 독립 변수는 나이와 성별 등 환자의 정보이며, 예측해야 하는 종속 변수는 당뇨병의 진행 정도이다. 자세한 사항은 [이곳](https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset)에서 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fd8ATeZHki6O"
   },
   "source": [
    "결측치가 없고 데이터 정규화(normalization)도 완료되어 있어, 제공된 그대로 분석에 사용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N_CsjIKRZEui"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ySBRllBAhToR"
   },
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "data = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aZhwSv5Wkz78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data :  [[ 0.03807591  0.05068012  0.06169621 ... -0.00259226  0.01990842\n",
      "  -0.01764613]\n",
      " [-0.00188202 -0.04464164 -0.05147406 ... -0.03949338 -0.06832974\n",
      "  -0.09220405]\n",
      " [ 0.08529891  0.05068012  0.04445121 ... -0.00259226  0.00286377\n",
      "  -0.02593034]\n",
      " ...\n",
      " [ 0.04170844  0.05068012 -0.01590626 ... -0.01107952 -0.04687948\n",
      "   0.01549073]\n",
      " [-0.04547248 -0.04464164  0.03906215 ...  0.02655962  0.04452837\n",
      "  -0.02593034]\n",
      " [-0.04547248 -0.04464164 -0.0730303  ... -0.03949338 -0.00421986\n",
      "   0.00306441]]\n",
      "target :  [151.  75. 141. 206. 135.  97. 138.  63. 110. 310. 101.  69. 179. 185.\n",
      " 118. 171. 166. 144.  97. 168.  68.  49.  68. 245. 184. 202. 137.  85.\n",
      " 131. 283. 129.  59. 341.  87.  65. 102. 265. 276. 252.  90. 100.  55.\n",
      "  61.  92. 259.  53. 190. 142.  75. 142. 155. 225.  59. 104. 182. 128.\n",
      "  52.  37. 170. 170.  61. 144.  52. 128.  71. 163. 150.  97. 160. 178.\n",
      "  48. 270. 202. 111.  85.  42. 170. 200. 252. 113. 143.  51.  52. 210.\n",
      "  65. 141.  55. 134.  42. 111.  98. 164.  48.  96.  90. 162. 150. 279.\n",
      "  92.  83. 128. 102. 302. 198.  95.  53. 134. 144. 232.  81. 104.  59.\n",
      " 246. 297. 258. 229. 275. 281. 179. 200. 200. 173. 180.  84. 121. 161.\n",
      "  99. 109. 115. 268. 274. 158. 107.  83. 103. 272.  85. 280. 336. 281.\n",
      " 118. 317. 235.  60. 174. 259. 178. 128.  96. 126. 288.  88. 292.  71.\n",
      " 197. 186.  25.  84.  96. 195.  53. 217. 172. 131. 214.  59.  70. 220.\n",
      " 268. 152.  47.  74. 295. 101. 151. 127. 237. 225.  81. 151. 107.  64.\n",
      " 138. 185. 265. 101. 137. 143. 141.  79. 292. 178.  91. 116.  86. 122.\n",
      "  72. 129. 142.  90. 158.  39. 196. 222. 277.  99. 196. 202. 155.  77.\n",
      " 191.  70.  73.  49.  65. 263. 248. 296. 214. 185.  78.  93. 252. 150.\n",
      "  77. 208.  77. 108. 160.  53. 220. 154. 259.  90. 246. 124.  67.  72.\n",
      " 257. 262. 275. 177.  71.  47. 187. 125.  78.  51. 258. 215. 303. 243.\n",
      "  91. 150. 310. 153. 346.  63.  89.  50.  39. 103. 308. 116. 145.  74.\n",
      "  45. 115. 264.  87. 202. 127. 182. 241.  66.  94. 283.  64. 102. 200.\n",
      " 265.  94. 230. 181. 156. 233.  60. 219.  80.  68. 332. 248.  84. 200.\n",
      "  55.  85.  89.  31. 129.  83. 275.  65. 198. 236. 253. 124.  44. 172.\n",
      " 114. 142. 109. 180. 144. 163. 147.  97. 220. 190. 109. 191. 122. 230.\n",
      " 242. 248. 249. 192. 131. 237.  78. 135. 244. 199. 270. 164.  72.  96.\n",
      " 306.  91. 214.  95. 216. 263. 178. 113. 200. 139. 139.  88. 148.  88.\n",
      " 243.  71.  77. 109. 272.  60.  54. 221.  90. 311. 281. 182. 321.  58.\n",
      " 262. 206. 233. 242. 123. 167.  63. 197.  71. 168. 140. 217. 121. 235.\n",
      " 245.  40.  52. 104. 132.  88.  69. 219.  72. 201. 110.  51. 277.  63.\n",
      " 118.  69. 273. 258.  43. 198. 242. 232. 175.  93. 168. 275. 293. 281.\n",
      "  72. 140. 189. 181. 209. 136. 261. 113. 131. 174. 257.  55.  84.  42.\n",
      " 146. 212. 233.  91. 111. 152. 120.  67. 310.  94. 183.  66. 173.  72.\n",
      "  49.  64.  48. 178. 104. 132. 220.  57.]\n",
      "frame :  None\n",
      "DESCR :  .. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "feature_names :  ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "data_filename :  c:\\users\\dksle\\appdata\\local\\programs\\python\\venv\\lib\\site-packages\\sklearn\\datasets\\data\\diabetes_data.csv.gz\n",
      "target_filename :  c:\\users\\dksle\\appdata\\local\\programs\\python\\venv\\lib\\site-packages\\sklearn\\datasets\\data\\diabetes_target.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "for k, v in data.items():\n",
    "  print(k, ': ', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRd7XyqknJKc"
   },
   "source": [
    "보다 편한 사용을 위해, 독립 변수를 x에 저장하고 종속 변수를 y에 저장하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2IOm3djDk-ky"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10) (442,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 저장 및 확인\n",
    "x = data['data']\n",
    "y = data['target']\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNkzvtpLnkO7"
   },
   "source": [
    "### 데이터 분할하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIuoZ8u3nny2"
   },
   "source": [
    "수업 시간에 배웠다시피, 적절한 모델을 학습시키기 위해서는 주어진 데이터를 training / validation / test 로 나누는 과정이 필수적이다. 아래처럼  scikit-learn에서 제공하는 [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) 함수를 이용하면 편리하게 데이터를 나눌 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GZ022PYApllm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9alcXtURppLj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 10) (89, 10) (89, 10)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 나누기 - 6:2:2 비율\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKHUNHZGpnJm"
   },
   "source": [
    "### 모델 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdeDRw67qwme"
   },
   "source": [
    "Training data를 이용해 회귀분석 모델을 학습해 보자. 먼저 아래와 같이 필요한 패키지를 import 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KLuvP9Kir3rB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRxCCfXbsdYC"
   },
   "source": [
    "Scikit-learn에서 제공하는 [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linearregression#sklearn.linear_model.LinearRegression) 모델에 대해 살펴보자. 이 객체를 선언할 때 필요한 주요 parameter는 다음과 같다.\n",
    "\n",
    "1.   fit_intercept: 상수항을 사용할 것인지에 대한 여부. True 일 때 상수항 사용. default=True\n",
    "2.   normalize: 정규화를 수행할 것인지에 대한 여부. True 일 때 정규화 수행. default=False\n",
    "\n",
    "이번 실습의 경우는 두 parameter 모두 default 값을 사용하면 된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZtVHQ_FwISx"
   },
   "source": [
    "이제 본격적으로 회귀분석 모델을 학습해 보자. Scikit-learn 모델의 학습을 위해 수행해야 할 작업은  \n",
    "\n",
    "1.   모델 객체 생성\n",
    "2.   데이터를 이용한 학습\n",
    "\n",
    "이 전부이다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fen6C2wNsRzI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 회귀분석 객체 생성\n",
    "mlr = LinearRegression()\n",
    "\n",
    "# 회귀분석 모델 학습\n",
    "mlr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ztgg-5Jzxf5w"
   },
   "source": [
    "추정한 모델의 회귀계수를 확인해 보자. 가장 영향력 있는 변수는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AdnRrmyLsUTb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.87388534119617\n",
      "[ -39.57865915 -236.60328634  489.97259328  352.8678163  -873.03276134\n",
      "  430.03354622  208.4341436   306.03221956  746.84762599  116.37588728]\n"
     ]
    }
   ],
   "source": [
    "# 회귀계수 확인\n",
    "print(mlr.intercept_)\n",
    "print(mlr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BO8fIzfyFQP"
   },
   "source": [
    "추정한 모델의 설명력을 확인해 보자. 수업 시간에 배운 결정계수 R-square를 계산하려면 우선 training data에 대한 예측값을 알아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FPGNsT6j1IGY"
   },
   "outputs": [],
   "source": [
    "# training data 예측값\n",
    "pred_train = mlr.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNwWDgBT1fwb"
   },
   "source": [
    "이제 scikit-learn에서 제공하는 r2_score 함수를 이용해 R-square 값을 계산해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9FxqzvnixnnR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5353262888595558\n"
     ]
    }
   ],
   "source": [
    "# training data에 대한 R-square 계산\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KeStIAJ103n"
   },
   "source": [
    "Validation data, test data의 R-sqaure 값도 같은 방법으로 계산해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5FgHaPSK1cmp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4934085901313141\n"
     ]
    }
   ],
   "source": [
    "# validation data에 대한 R-square 계산\n",
    "pred_val = mlr.predict(x_val)\n",
    "print(r2_score(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6jFY-pG4EsQ7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4432722010710277\n"
     ]
    }
   ],
   "source": [
    "# test data에 대한 R-square 계산\n",
    "pred_test = mlr.predict(x_test)\n",
    "print(r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbTCqRZz-7zL"
   },
   "source": [
    "### 모델 선택하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYSs0obE-tQ3"
   },
   "source": [
    "수업 시간에 배운 단계적 회귀분석법 중 하나인 전진 선택법을 구현해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhHbKIzx_VEd"
   },
   "source": [
    "전진 선택법은 상수항만 있는 모형에서 시작해, 설명력을 가장 크게 높일 수 있는 변수부터 하나씩 추가해 나가는 방법이다. 더 이상 설명력의 이득이 없을 때까지 변수를 추가한다. 원래는 F 검정을 기준으로 사용해야 하지만, 간단한 구현을 위해 R-square 로 대체하자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzE_cExpnhG2"
   },
   "source": [
    "공집합에서 시작해, 매 반복마다 남아 있는 변수들 중 \"추가했을 때 R-square 가 가장 큰 변수\"를 기존의 변수집합에 더해 나가는 방식으로 구현해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8qzSW2MF3EWH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ round 1 ============\n",
      "best variables updated:  [2]\n",
      "current best r2:  0.4015039066196986\n",
      "============ round 2 ============\n",
      "best variables updated:  [2, 8]\n",
      "current best r2:  0.48019951742375155\n",
      "============ round 3 ============\n",
      "best variables updated:  [2, 8, 6]\n",
      "current best r2:  0.4911801371957262\n",
      "============ round 4 ============\n",
      "best variables updated:  [2, 8, 6, 1]\n",
      "current best r2:  0.514245907690211\n",
      "============ round 5 ============\n",
      "best variables updated:  [2, 8, 6, 1, 3]\n",
      "current best r2:  0.5333863843789601\n",
      "============ round 6 ============\n",
      "no improvement\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "final variables:  [1, 2, 3, 6, 8]\n",
      "final r2:  0.5333863843789601\n"
     ]
    }
   ],
   "source": [
    "# 선택된 변수들, R-square 값 및 모델 저장\n",
    "best_variables = []\n",
    "best_r2 = 0.\n",
    "best_model = None\n",
    "\n",
    "# 남아 있는 변수들\n",
    "remain_variables = list(range(10))\n",
    "\n",
    "for round in range(10):\n",
    "  print(f\"============ round {round+1} ============\")\n",
    "  r2_of_this_round = []\n",
    "  models_of_this_round = []\n",
    "\n",
    "  for var in remain_variables:\n",
    "    # 사용될 변수들과 모델\n",
    "    use_vars = best_variables + [var]\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # 지정된 변수만 사용하게끔 데이터 추출\n",
    "    x_train_small = x_train[:, use_vars]\n",
    "    x_val_small = x_val[:, use_vars]\n",
    "\n",
    "    # 지정된 변수로 모델 학습\n",
    "    model.fit(x_train_small, y_train)\n",
    "    models_of_this_round.append(model)\n",
    "\n",
    "    # validation R-square 계산\n",
    "    r2 = r2_score(y_val, model.predict(x_val_small))\n",
    "    r2_of_this_round.append(r2)\n",
    "  \n",
    "  # R-square 가 높은 모델 선택\n",
    "  best_r2_of_this_round = np.max(r2_of_this_round)\n",
    "\n",
    "  # 이전 round와 비교\n",
    "  if best_r2_of_this_round > best_r2:\n",
    "    best_var_of_this_round = np.argmax(r2_of_this_round)\n",
    "\n",
    "    # 변수 추가, R-square 값 및 모델 업데이트\n",
    "    best_variables.append(remain_variables[best_var_of_this_round])\n",
    "    best_r2 = best_r2_of_this_round\n",
    "    best_model = models_of_this_round[best_var_of_this_round]\n",
    "\n",
    "    # 남은 변수들 중 선택된 변수 제거\n",
    "    remain_variables.pop(best_var_of_this_round)\n",
    "\n",
    "    print('best variables updated: ', best_variables)\n",
    "    print('current best r2: ', best_r2)\n",
    "\n",
    "  # 더 이상 개선되지 않으면 멈춤  \n",
    "  else:\n",
    "    print(\"no improvement\")\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "print('\\n---------------------------------------------------\\n')\n",
    "print('final variables: ', sorted(best_variables))\n",
    "print('final r2: ', best_r2)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Bp2HnGDA6FyC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42090782097560653\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test, best_model.predict(x_test[:, best_variables])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilLoaGaPIWUf"
   },
   "source": [
    "결정계수 R-square 를 알고 있을 때, 수정 결정계수 adjusted R-square 를 다음과 같이 계산할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BngmopDXIj41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37189684223398\n"
     ]
    }
   ],
   "source": [
    "# test data에 대한 adjust R-square 계산\n",
    "pred_test = mlr.predict(x_test)\n",
    "test_r2 = r2_score(y_test, pred_test)\n",
    "test_adj_r2 = 1-(1-test_r2)*(y_test.size-1)/(y_test.size-x_test.shape[1]-1)\n",
    "print(test_adj_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhyFXKU8JDK6"
   },
   "source": [
    "Adjusted R-square 를 이용하여 후진 제거법 알고리즘을 구현해 보자. (실습!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "UtZOc2skBol0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ round 1 ============\n",
      "============ round 2 ============\n",
      "============ round 3 ============\n",
      "============ round 4 ============\n",
      "============ round 5 ============\n",
      "============ round 6 ============\n",
      "============ round 7 ============\n",
      "============ round 8 ============\n",
      "============ round 9 ============\n",
      "============ round 10 ============\n",
      "---------------------------------------------------\n",
      "final variables:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "final adj_r2:  0.0\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-45b6501b0955>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'---------------------------------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtest_r2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_variables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mtest_adj_r2\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtest_r2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test adjust R-square: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_adj_r2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# 선택된 변수들, R-square 값 및 모델 저장\n",
    "best_variables = list(range(10))\n",
    "best_adj_r2 = 0.\n",
    "best_model = None\n",
    "\n",
    "\n",
    "# TODO: 선택된 변수들 중 Adjusted R-square의 손실이 가장 적은 변수를 골라 없애기\n",
    "for round in range(10):\n",
    "  print(f\"============ round {round+1} ============\")\n",
    "  adj_r2_of_this_round = []\n",
    "  models_of_this_round = []\n",
    "\n",
    "  for var in best_variables:\n",
    "    pass\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "print('final variables: ', sorted(best_variables))\n",
    "print('final adj_r2: ', best_adj_r2)\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "test_r2=r2_score(y_test, best_model.predict(x_test[:, best_variables]))\n",
    "test_adj_r2 =1-(1-test_r2)*(y_test.shape[0]-1)/(y_test.shape[0]-len(best_variables)-1) \n",
    "print('test adjust R-square: ', test_adj_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXrp1dTRq88a"
   },
   "source": [
    "### 회귀모형의 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6p0jQwkTrIXh"
   },
   "source": [
    "수업 시간에 배운 회귀모형의 검정 및 진단을 실행해 보자. 아쉽게도 scikit-learn 에서는 해당 분석을 제공하지 않고 있다. 이를 제공하는 새로운 패키지인 statsmodels 를 사용해 보자.\n",
    "Statsmodels 패키지에서는 OLS 라는 클래스를 이용하여 회귀분석을 진행한다. 아래와 같은 방식으로 학습을 진행하고 각종 테스트 결과를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4UBggEa90oU"
   },
   "source": [
    "Scikit-learn에서와 다른 점 중 하나는 객체를 생성할 때 데이터를 미리 입력해주어야 한다는 것이고, 또 하나는 상수항을 따로 추가해 주어야 한다는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "IZvpmb5Nq78m"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e9022d2decd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOLS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "EE_jEw8Yryqh"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OLS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-3f6984515db2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msm_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msm_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msm_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OLS' is not defined"
     ]
    }
   ],
   "source": [
    "sm_model = OLS(y_train, statsmodels.api.add_constant(x_train))\n",
    "\n",
    "sm_model = sm_model.fit()\n",
    "print(sm_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-daT9zECv1iY"
   },
   "source": [
    "다중공선성을 확인할 수 있는 VIF를 계산해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "LNK-iS8IvpkV"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d8fbd8280798>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutliers_influence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvariance_inflation_factor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "PweXY7Fmv6Jp"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'variance_inflation_factor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-cc0b497e2cd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"VIF of x{i+1}: {variance_inflation_factor(x_train, i):.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'variance_inflation_factor' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(x_train.shape[1]):\n",
    "  print(f\"VIF of x{i+1}: {variance_inflation_factor(x_train, i):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDUU_dHCv57N"
   },
   "source": [
    "다중공선성이 확인된 변수를 제외한 모델을 학습해 보자. (실습!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNy32rfewwJC"
   },
   "outputs": [],
   "source": [
    "# Todo: 다중공선성이 확인된 변수들을 제외하고 회귀분석 학습하고 결과 출력하기(statsmodels 이용)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUtTj8qIAfPZ"
   },
   "source": [
    "마지막으로 잔차분석을 위해 잔차 그래프를 그려보자. Matplotlib 패키지의 scatter 함수를 이용해서 아래와 같이 그려볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmsYWHs5AdJr"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(pred_train, y_train - pred_train)\n",
    "plt.plot([pred_train.min(), pred_train.max()], [0, 0], '--', color='grey')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1_Linear_Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
