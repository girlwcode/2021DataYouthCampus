{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4_Support_Vector_Machine.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qV40U7mLZkN4"},"source":["# 서포트 벡터 머신 실습"]},{"cell_type":"markdown","metadata":{"id":"AqnaCOhoZsTc"},"source":["python의 scikit-learn 패키지를 이용해 서포트 벡터 머신을 직접 실행해보자."]},{"cell_type":"markdown","metadata":{"id":"h5X9HqjFaFVK"},"source":["### 데이터 불러오기 및 분할하기"]},{"cell_type":"markdown","metadata":{"id":"an123w8zaJKA"},"source":["로지스틱 회귀분석 때 사용했던 [cancer dataset](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-wisconsin-diagnostic-dataset)을 그대로 사용하자."]},{"cell_type":"code","metadata":{"id":"0KlWlN1wZTfo"},"source":["from sklearn import datasets\n","import numpy as np\n","data = datasets.load_breast_cancer()\n","\n","x = data['data']\n","y = data['target']\n","\n","print(x.shape, y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ckvS6U2caWnX"},"source":["from sklearn.model_selection import train_test_split\n","\n","# 데이터 나누기 - 6:2:2 비율\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n","\n","print(x_train.shape, x_val.shape, x_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wuuUF8A4aaGW"},"source":["### 모델 학습 및 평가하기"]},{"cell_type":"markdown","metadata":{"id":"TcBMmFjsawNo"},"source":["Scikit-learn에서 제공하는 [svm](https://scikit-learn.org/stable/modules/classes.html?highlight=svm#module-sklearn.svm) 모듈에는 다양한 서포트 벡터 관련 모델이 포함되어 있다. 이들 중 [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)(Support Vector Classifier)가 수업 시간에 배웠던 서포트 벡터 머신에 해당한다. 입력 변수를 살펴보면, kernel이나 C 값 등을 조절할 수 있다는 것을 알 수 있다."]},{"cell_type":"code","metadata":{"id":"H-G7hjr-cXzJ"},"source":["from sklearn.svm import SVC"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ywT_bZuab92T"},"source":["먼저 linear SVM을 학습하고 validation data에 대한 분류 accuracy를 계산해 보자."]},{"cell_type":"code","metadata":{"id":"fNt9m6cCav4g"},"source":["# linear SVM 학습하기\n","linear_svm = SVC(kernel='linear')\n","linear_svm.fit(x_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"egtLXTYXaZbh"},"source":["# linear SVM accuracy 계산하기\n","from sklearn.metrics import accuracy_score\n","pred_val = linear_svm.predict(x_val)\n","print(f\"accuracy:{accuracy_score(y_val, pred_val)}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CXlsh8YbctVs"},"source":["다음으로, for문 등을 이용해 다양한 커널로 SVM 모델을 학습해 보자. (실습!)"]},{"cell_type":"code","metadata":{"id":"d8ARMY0yctBR"},"source":["# TODO: 여러 가지 kernel을 사용해 SVM 학습하고 accuracy 계산하기\n","kernels = ['poly','rbf','sigmoid']\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KehtZou9dHXd"},"source":["수업 시간에 RBF(가우시안) 커널을 사용할 때 C와 gamma의 변화에 따른 결정 경계의 변화를 설명한 바 있다. 이를 확인하기 위해, C와 gamma의 값을 아래의 네 가지 종류 중에서 골라 총 16가지의 조합에 대한 SVM을 학습하고 분류 accuracy를 계산해 보자. (실습!)"]},{"cell_type":"code","metadata":{"id":"uK1Y8xsEdq4F"},"source":["# TODO: 각 조합에 대해 SVM 학습하고 accuracy 계산하기\n","C = [1, 10, 100, 1000]\n","Gamma = [0.00001, 0.0001, 0.001, 0.01]        \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XCnr4Pjc1GV8"},"source":["위의 경우 중 가장 우수한 모델을 이용해 test data에서의 정확도를 확인해 보자. (실습!)"]},{"cell_type":"code","metadata":{"id":"bp06dSl2z6HY"},"source":["# TODO: 가장 좋다고 판단되는 SVM 모델로 test data 에 대한 정확도 확인하기\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5f_OJ7LmE-o"},"source":["### Grid Search"]},{"cell_type":"markdown","metadata":{"id":"Z1euiGE0mI0J"},"source":["위와 같이 다양한 하이퍼파라미터의 조합을 실험하여 최적의 조합을 찾는 것을 Grid Search 라 한다. "]},{"cell_type":"markdown","metadata":{"id":"6PDNljZ_m51d"},"source":["![](https://miro.medium.com/max/700/1*Xq9OvMKXhrF3W2RBJCWW7w.png)"]},{"cell_type":"markdown","metadata":{"id":"Wm6FQSGRnaWn"},"source":["Scikit-learn에서는 Grid Search와 cross validation을 함께 수행하는 [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearch#sklearn.model_selection.GridSearchCV) 모듈을 제공하고 있다. 이를 이용해서 위의 작업을 보다 간단히 수행해 보자."]},{"cell_type":"code","metadata":{"id":"LldtKaC9no8q"},"source":["from sklearn.model_selection import GridSearchCV\n","\n","# GridSearchCV에서 cross validation을 하므로, validation data가 필요없음\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n","\n","# 아래와 같이 탐색할 조합들을 지정\n","param_grid = {'C': [1, 10, 100, 1000], \n","              'gamma': [0.00001, 0.0001, 0.001, 0.01]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_jbQbP_o_We"},"source":["# GridSearchCV를 이용하여 분류하기\n","svm_grid = GridSearchCV(estimator=SVC(), param_grid=param_grid, cv=4, scoring='accuracy')\n","svm_grid.fit(x_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T4HqVNx5q6Wr"},"source":["# 최적의 조합과 그 때의 점수 알아보기\n","print(svm_grid.best_params_)\n","print(svm_grid.best_score_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WUbQxgEjec1_"},"source":["### 추가 예제: Face Recognition"]},{"cell_type":"markdown","metadata":{"id":"f0Ca8qLGfD-M"},"source":["SVM의 우수한 성능에 대해 수업 시간에 언급한 바 있다. 이를 체감할 수 있는 좋은 예시 중 하나가 대표적인 패턴 인식 문제인 Face Recognition이다. Face Recognition에서 SVM이 어떻게 적용되며 어떤 성능을 낼 수 있는지 알아보자. "]},{"cell_type":"code","metadata":{"id":"2EiPJCqBfDT0"},"source":["from sklearn.datasets import fetch_lfw_people\n","faces = fetch_lfw_people(min_faces_per_person=60)\n","print(faces.target_names)\n","print(faces.images.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"emtXetwSgM4v"},"source":["아래의 코드를 통해 데이터의 일부를 확인해 볼 수 있다."]},{"cell_type":"code","metadata":{"id":"v5pU4QJqf4zv"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","fig, ax = plt.subplots(3, 5)\n","for i, axi in enumerate(ax.flat):\n","    axi.imshow(faces.images[i], cmap='bone')\n","    axi.set(xticks=[], yticks=[],\n","            xlabel=faces.target_names[faces.target[i]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x0ajnq_jjbsM"},"source":["일반적인 SVM은 범주가 두 종류여야 잘 작동하는데, 주어진 데이터는 분류해야 할 범주가 여러 개이다. 그러나 SVC 객체는 이러한 경우에 대해서도 잘 작동할 수 있도록 구성되어 있다. [설명](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)을 잘 읽어보면서 수업 시간에 배웠던, 두 가지 이상의 범주를 분류하는 방법이 어디에 나와 있는지 한 번 찾아보자."]},{"cell_type":"markdown","metadata":{"id":"yyDwvOc3r1Lg"},"source":["종속 변수의 분포를 살펴보면, 아래와 같이 특정 데이터가 두드러지게 많다는 것을 확인할 수 있다. 수업 때 언급했듯이 이러한 data imbalance 문제는 머신 러닝에서 주의 깊게 다뤄야 할 부분이다. "]},{"cell_type":"code","metadata":{"id":"j4aBwn1LTe4k"},"source":["import collections\n","\n","count_faces = collections.Counter(faces.target)\n","print(faces.target, ' => ', count_faces)\n","\n","names = [x.split(' ')[-1] for x in faces.target_names]\n","counts = [count_faces[i] for i in range(len(faces.target_names))]\n","plt.bar(names, counts)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fOKHFDAVh504"},"source":["앞서 배운 GridSearchCV를 사용하기 위해, training / test data 로 나누자."]},{"cell_type":"code","metadata":{"id":"42clXB3kh0tT"},"source":["from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(faces.data, faces.target, test_size=0.2, random_state=1)\n","print(x_train.shape, x_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uo7jVud4SQd4"},"source":["가우시안 커널을 사용하면 이러한 데이터도 효과적으로 분류할 수 있다. 앞서 언급한 data imbalance 문제를 해결하기 위해, class_weight 파라미터를 이용하자. (실습!)"]},{"cell_type":"code","metadata":{"id":"DJ6Q2vRr3Ee0"},"source":["# TODO: class_weight 파라미터를 활용하여 SVM 학습하기"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gQmpGJs43qyS"},"source":["# 학습한 모델로 정확도 및 confusion matrix 구하기\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import seaborn as sns\n","\n","pred_test = svm.predict(x_test)\n","print(\"accuracy: \", accuracy_score(y_test, pred_test))\n","\n","mat = confusion_matrix(y_test, pred_test)\n","sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n","            xticklabels=faces.target_names,\n","            yticklabels=faces.target_names)\n","plt.xlabel('true label')\n","plt.ylabel('predicted label')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ga3OP2QFgeKD"},"source":["주어진 데이터(사진)의 크기는 62*47=2914 픽셀로, 그 동안 다루었던 데이터에 비해 상당히 큰 차원이다. 이를 적정 수준으로 줄여 주기 위해, [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html?highlight=pca#sklearn.decomposition.PCA)를 시행한다. 이를 통해 2914차원의 데이터를 150차원으로 줄일 수 있다."]},{"cell_type":"code","metadata":{"id":"5kXggLOMgXEj"},"source":["from sklearn.decomposition import PCA\n","\n","pca = PCA(n_components=150, whiten=True, random_state=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZOQuTskriPQM"},"source":["링크를 참조하여 PCA를 training 데이터로 학습하고, 이를 다시 training 데이터에 적용하여 얻은 150차원 데이터를 x_pca_train 이라 하자. (실습!)"]},{"cell_type":"code","metadata":{"id":"Nsr59B4PiuXD"},"source":["# TODO: PCA 학습 및 적용하기\n","\n","x_pca_train = "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cv2dsiKPhFSU"},"source":["150차원으로 줄어든 데이터에 대해 SVM 모델을 학습한다."]},{"cell_type":"code","metadata":{"id":"nZF13hRXg8aL"},"source":["svm_pca = SVC(kernel='rbf', class_weight='balanced')\n","svm_pca.fit(x_pca_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K8yL9skrjHu3"},"source":["Test data에 대한 예측 결과를 pred_pca_test 라고 하고 accuracy와 confusion matrix를 통해 분류가 잘 되었는지 확인해 보자. (실습!)"]},{"cell_type":"code","metadata":{"id":"XzOB0JQzlY14"},"source":["# TODO: test data에 대한 예측 수행하기\n","\n","pred_pca_test = "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-5TMk8BGklws"},"source":["print(\"accuracy: \", accuracy_score(y_test, pred_pca_test))\n","mat = confusion_matrix(y_test, pred_pca_test)\n","sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n","            xticklabels=faces.target_names,\n","            yticklabels=faces.target_names)\n","plt.xlabel('true label')\n","plt.ylabel('predicted label')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wx2ZQBKmuMUE"},"source":["아래의 코드를 수행하면, test data에 대한 예측이 맞았는지를 직접 살펴볼 수 있다."]},{"cell_type":"code","metadata":{"id":"94E7_0FTkWgH"},"source":["fig, ax = plt.subplots(3, 5)\n","for i, axi in enumerate(ax.flat):\n","    axi.imshow(x_test[i].reshape(62, 47), cmap='bone')\n","    axi.set(xticks=[], yticks=[])\n","    axi.set_ylabel(faces.target_names[pred_pca_test[i]].split()[-1],\n","                   color='black' if pred_pca_test[i] == y_test[i] else 'red')\n","fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XsUww75sxD5z"},"source":["앞서 배운 GridSearchCV를 이용하여 최적의 조합을 찾아보자. (실습!)"]},{"cell_type":"code","metadata":{"id":"RiVQm9_6wSh6"},"source":["# TODO: param_grid 및 GridSearchCV 객체 생성 후 학습하고 최적의 조합 찾기\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SBIf_afGxSa-"},"source":["이를 test data에 대해 적용한 결과를 확인해 보자. (실습!)"]},{"cell_type":"code","metadata":{"id":"j2REmtvdwmzq"},"source":["# TODO: GridSearchCV로 찾은 조합의 모델로 accuracy와 confusion matrix 그리기\n","pred_pca_grid_test = \n","\n","print(\"accuracy: \", accuracy_score(y_test, pred_pca_grid_test))\n","mat = confusion_matrix(y_test, pred_pca_grid_test)\n","sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n","            xticklabels=faces.target_names,\n","            yticklabels=faces.target_names)\n","plt.xlabel('true label')\n","plt.ylabel('predicted label')"],"execution_count":null,"outputs":[]}]}